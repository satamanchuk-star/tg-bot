"""ÐŸÐ¾Ñ‡ÐµÐ¼Ñƒ: Ð¸Ð½ÐºÐ°Ð¿ÑÑƒÐ»Ð¸Ñ€ÑƒÐµÐ¼ Ð˜Ð˜-Ð¿Ð¾Ð»Ð¸Ñ‚Ð¸ÐºÑƒ, Ð»Ð¸Ð¼Ð¸Ñ‚Ñ‹ Ð¸ fallback Ð² Ð¾Ð´Ð½Ð¾Ð¼ Ð¼ÐµÑÑ‚Ðµ."""

from __future__ import annotations

import json
import logging
import re
import time
from dataclasses import dataclass
from datetime import datetime, timedelta
from typing import Awaitable, Callable, Literal

import httpx

from app.config import settings
from app.db import get_session
from app.services.ai_usage import add_usage, can_consume_ai, get_usage_stats
from app.utils.time import now_tz

logger = logging.getLogger(__name__)

MODERATION_SYSTEM_PROMPT = """Ð¢Ñ‹ â€” Ð¼Ð¾Ð´ÐµÑ€Ð°Ñ‚Ð¾Ñ€ Ñ‡Ð°Ñ‚Ð° Ð¶Ð¸Ð»Ð¾Ð³Ð¾ ÐºÐ¾Ð¼Ð¿Ð»ÐµÐºÑÐ°.\n\nÐ¢Ð²Ð¾Ñ Ð·Ð°Ð´Ð°Ñ‡Ð° â€” Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ Ð¸ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÑÑ‚ÑŒ:\n- Ð½Ð°Ð»Ð¸Ñ‡Ð¸Ðµ Ð¼Ð°Ñ‚Ð° (Ð²ÐºÐ»ÑŽÑ‡Ð°Ñ Ð·Ð°Ð¼Ð°ÑÐºÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹),\n- Ð³Ñ€ÑƒÐ±Ð¾ÑÑ‚ÑŒ,\n- Ð°Ð³Ñ€ÐµÑÑÐ¸ÑŽ,\n- ÑƒÐ³Ñ€Ð¾Ð·Ñ‹.\n\nÐ¢Ñ‹ Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑˆÑŒ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ JSON Ð±ÐµÐ· Ð¿Ð¾ÑÑÐ½ÐµÐ½Ð¸Ð¹.\n\nÐ£Ñ‡Ð¸Ñ‚Ñ‹Ð²Ð°Ð¹ Ð·Ð°Ð¼ÐµÐ½Ñ‹ Ð±ÑƒÐºÐ² ÑÐ¸Ð¼Ð²Ð¾Ð»Ð°Ð¼Ð¸, Ð¿Ñ€Ð¾Ð±ÐµÐ»Ñ‹ Ð¼ÐµÐ¶Ð´Ñƒ Ð±ÑƒÐºÐ²Ð°Ð¼Ð¸, Ð»Ð°Ñ‚Ð¸Ð½Ð¸Ñ†Ñƒ Ð²Ð¼ÐµÑÑ‚Ð¾ ÐºÐ¸Ñ€Ð¸Ð»Ð»Ð¸Ñ†Ñ‹, Ñ†Ð¸Ñ„Ñ€Ñ‹, Ñ‚Ñ€Ð°Ð½ÑÐ»Ð¸Ñ‚ÐµÑ€Ð°Ñ†Ð¸ÑŽ Ð¸ Ñ‡Ð°ÑÑ‚Ð¸Ñ‡Ð½Ð¾ ÑÐºÑ€Ñ‹Ñ‚Ñ‹Ðµ ÑÐ»Ð¾Ð²Ð°.\nÐœÐ°Ñ‚ ÑÑ‡Ð¸Ñ‚Ð°ÐµÑ‚ÑÑ Ð½Ð°Ñ€ÑƒÑˆÐµÐ½Ð¸ÐµÐ¼ Ð´Ð°Ð¶Ðµ ÐµÑÐ»Ð¸ Ð¾Ð½ Ð·Ð°Ð¼Ð°ÑÐºÐ¸Ñ€Ð¾Ð²Ð°Ð½.\n\nÐ£Ñ€Ð¾Ð²Ð½Ð¸ severity:\n0 â€” Ð½ÐµÑ‚ Ð½Ð°Ñ€ÑƒÑˆÐµÐ½Ð¸Ñ\n1 â€” Ð¼ÑÐ³ÐºÐ°Ñ Ð³Ñ€ÑƒÐ±Ð¾ÑÑ‚ÑŒ\n2 â€” ÑÐ²Ð½Ð¾Ðµ Ð½Ð°Ñ€ÑƒÑˆÐµÐ½Ð¸Ðµ\n3 â€” ÑÐµÑ€ÑŒÑ‘Ð·Ð½Ð¾Ðµ Ð½Ð°Ñ€ÑƒÑˆÐµÐ½Ð¸Ðµ\n\nÐ¤Ð¾Ñ€Ð¼Ð°Ñ‚ Ð¾Ñ‚Ð²ÐµÑ‚Ð°:\n{\n  \"label\": \"PROFANITY|RUDE|HATE|THREAT|NONE\",\n  \"severity\": 0,\n  \"confidence\": 0.0,\n  \"recommended_action\": \"ALLOW|WARN|DELETE|STRIKE|ADMIN_ALERT\",\n  \"user_message\": \"ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ°Ñ Ð¶Ð¸Ð²Ð°Ñ Ñ„Ñ€Ð°Ð·Ð°\",\n  \"admin_note\": \"ÐºÑ€Ð°Ñ‚ÐºÐ¾Ðµ Ð¿Ð¾ÑÑÐ½ÐµÐ½Ð¸Ðµ Ð´Ð»Ñ Ð°Ð´Ð¼Ð¸Ð½Ð¾Ð²\"\n}\n\nÐŸÑ€Ð°Ð²Ð¸Ð»Ð°:\n- ÐÐ¸ÐºÐ°ÐºÐ¾Ð³Ð¾ Ñ‚ÐµÐºÑÑ‚Ð° Ð²Ð½Ðµ JSON.\n- user_message Ð´Ð¾ 200 ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð².\n- Ð¡Ð¿Ð¾ÐºÐ¾Ð¹Ð½Ñ‹Ð¹ Ð¶Ð¸Ð²Ð¾Ð¹ Ñ‚Ð¾Ð½ Ð±ÐµÐ· ÐºÐ°Ð½Ñ†ÐµÐ»ÑÑ€Ð¸Ñ‚Ð°.\n- ÐÐµ ÑƒÐ¿Ð¾Ð¼Ð¸Ð½Ð°Ñ‚ÑŒ Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼Ñ‹, Ð˜Ð˜ Ð¸Ð»Ð¸ ÑÐ¸ÑÑ‚ÐµÐ¼Ñƒ.\n"""

ASSISTANT_SYSTEM_PROMPT = """Ð¢Ñ‹ â€” ÑƒÑ‡Ð°ÑÑ‚Ð½Ð¸Ðº Ñ‡Ð°Ñ‚Ð° Ð¶Ð¸Ð»Ð¾Ð³Ð¾ ÐºÐ¾Ð¼Ð¿Ð»ÐµÐºÑÐ°.\nÐžÑ‚Ð²ÐµÑ‡Ð°Ð¹ ÐºÐ°Ðº Ð¶Ð¸Ð²Ð¾Ð¹ Ñ‡ÐµÐ»Ð¾Ð²ÐµÐº: ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¾, Ð´Ñ€ÑƒÐ¶ÐµÐ»ÑŽÐ±Ð½Ð¾, ÑÐ¿Ð¾ÐºÐ¾Ð¹Ð½Ð¾, Ð¿Ð¾ Ð´ÐµÐ»Ñƒ.\nÐ”Ð¾Ð¿ÑƒÑÐºÐ°ÐµÑ‚ÑÑ Ð»Ñ‘Ð³ÐºÐ¸Ð¹ Ð½ÐµÐ¹Ñ‚Ñ€Ð°Ð»ÑŒÐ½Ñ‹Ð¹ ÑŽÐ¼Ð¾Ñ€ Ð±ÐµÐ· ÑÐ°Ñ€ÐºÐ°Ð·Ð¼Ð°.\n\nÐ—Ð°Ð¿Ñ€ÐµÑ‰ÐµÐ½Ð¾: \"ÐºÐ°Ðº Ð˜Ð˜\", ÑƒÐ¿Ð¾Ð¼Ð¸Ð½Ð°Ð½Ð¸Ñ Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼Ð¾Ð² Ð¸ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ð¹ Ð¼Ð¾Ð´ÐµÑ€Ð°Ñ†Ð¸Ð¸, ÐºÐ°Ð½Ñ†ÐµÐ»ÑÑ€Ð¸Ñ‚, Ð¼Ð¾Ñ€Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ñ‚Ð¾Ð½.\nÐÐµ Ð´Ð°Ð²Ð°Ð¹ Ð¼ÐµÐ´Ð¸Ñ†Ð¸Ð½ÑÐºÐ¸Ðµ, ÑŽÑ€Ð¸Ð´Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð¸ Ñ„Ð¸Ð½Ð°Ð½ÑÐ¾Ð²Ñ‹Ðµ ÑÐ¾Ð²ÐµÑ‚Ñ‹, Ð½Ðµ Ð¾Ð±ÑÑƒÐ¶Ð´Ð°Ð¹ Ð¿Ð¾Ð»Ð¸Ñ‚Ð¸ÐºÑƒ Ð¸ Ñ€ÐµÐ»Ð¸Ð³Ð¸ÑŽ.\nÐ•ÑÐ»Ð¸ Ñ‚ÐµÐ¼Ð° Ð²Ð½Ðµ Ð·Ð¾Ð½Ñ‹ â€” Ð¼ÑÐ³ÐºÐ¾ Ð¾Ñ‚ÐºÐ°Ð¶Ð¸: \"Ð¡ ÑÑ‚Ð¸Ð¼ Ð»ÑƒÑ‡ÑˆÐµ Ðº Ð¿Ñ€Ð¾Ñ„Ð¸Ð»ÑŒÐ½Ð¾Ð¼Ñƒ ÑÐ¿ÐµÑ†Ð¸Ð°Ð»Ð¸ÑÑ‚Ñƒ ðŸ™Œ Ð¯ Ñ‚ÑƒÑ‚ Ð±Ð¾Ð»ÑŒÑˆÐµ Ð¿Ñ€Ð¾ Ð¶Ð¸Ð·Ð½ÑŒ Ð´Ð¾Ð¼Ð°.\"\n\nÐžÐ³Ñ€Ð°Ð½Ð¸Ñ‡ÐµÐ½Ð¸Ñ: Ð¼Ð°ÐºÑÐ¸Ð¼ÑƒÐ¼ 800 ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð², Ð±ÐµÐ· Ñ‚Ð°Ð±Ð»Ð¸Ñ† Ð¸ Ð´Ð»Ð¸Ð½Ð½Ñ‹Ñ… Ð°Ð±Ð·Ð°Ñ†ÐµÐ².\nÐ•ÑÐ»Ð¸ ÐµÑÑ‚ÑŒ ÐºÐ¾Ð½Ñ„Ð»Ð¸ÐºÑ‚, Ð¼ÑÐ³ÐºÐ¾ Ð´ÐµÑÑÐºÐ°Ð»Ð¸Ñ€ÑƒÐ¹: \"ÐœÐ¾Ð¶Ð½Ð¾ ÑÐ¿Ð¾Ñ€Ð¸Ñ‚ÑŒ, Ð½Ð¾ ÑÐ¿Ð¾ÐºÐ¾Ð¹Ð½Ð¾.\"\n"""

DAILY_SUMMARY_SYSTEM_PROMPT = """Ð¢Ñ‹ â€” Ð¿Ð¾Ð¼Ð¾Ñ‰Ð½Ð¸Ðº Ð¼Ð¾Ð´ÐµÑ€Ð°Ñ‚Ð¾Ñ€Ð¾Ð². Ð¡Ð¾ÑÑ‚Ð°Ð²ÑŒ ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÑƒÑŽ ÑÐ²Ð¾Ð´ÐºÑƒ Ð´Ð½Ñ Ð¿Ð¾ Ð²Ñ…Ð¾Ð´Ð½Ð¾Ð¼Ñƒ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ñƒ.
Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚: 4-6 Ð¼Ð°Ñ€ÐºÐµÑ€Ð¾Ð², Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ñ„Ð°ÐºÑ‚Ñ‹ Ð¸ Ð¿Ð¾Ð»ÐµÐ·Ð½Ñ‹Ðµ Ð²Ñ‹Ð²Ð¾Ð´Ñ‹. Ð¢Ð¾Ð½ Ð½ÐµÐ¹Ñ‚Ñ€Ð°Ð»ÑŒÐ½Ñ‹Ð¹.
ÐÐµ Ð¿Ñ€Ð¸Ð´ÑƒÐ¼Ñ‹Ð²Ð°Ð¹ Ñ„Ð°ÐºÑ‚Ñ‹ Ð¸ Ð½Ðµ ÑƒÐ¿Ð¾Ð¼Ð¸Ð½Ð°Ð¹ Ð˜Ð˜. ÐœÐ°ÐºÑÐ¸Ð¼ÑƒÐ¼ 900 ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð²."""

_USER_FALLBACK = "AI Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ð¾ Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½, Ð²ÐºÐ»ÑŽÑ‡ÐµÐ½ ÑƒÐ¿Ñ€Ð¾Ñ‰ÐµÐ½Ð½Ñ‹Ð¹ Ñ€ÐµÐ¶Ð¸Ð¼."

_ALLOWED_ASSISTANT_TOPICS = (
    "Ð¶Ðº",
    "Ð´Ð²Ð¾Ñ€",
    "Ð¿Ð¾Ð´ÑŠÐµÐ·Ð´",
    "Ð¿Ð°Ñ€ÐºÐ¾Ð²",
    "ÑˆÐ»Ð°Ð³Ð±Ð°ÑƒÐ¼",
    "Ð¸Ð½Ñ„Ñ€Ð°ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€",
    "Ñ€ÐµÐ¼Ð¾Ð½Ñ‚",
    "ÑÐ¾ÑÐµÐ´",
    "Ð±Ñ‹Ñ‚",
    "ÐºÐ¾Ð¼Ð¼ÑƒÐ½",
    "Ð´Ð¾Ð¼",
    "ÐºÐ²Ð°Ñ€Ñ‚Ð¸Ñ€Ð°",
)
_FORBIDDEN_ASSISTANT_TOPICS = (
    "Ð¿Ð¾Ð»Ð¸Ñ‚",
    "Ñ€ÐµÐ»Ð¸Ð³Ð¸",
    "Ð½Ð°Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒ",
    "Ð¼ÐµÐ´Ð¸Ñ†Ð¸Ð½",
    "Ð´Ð¸Ð°Ð³Ð½Ð¾Ð·",
    "ÑŽÑ€Ð¸Ð´",
    "ÑÑƒÐ´",
    "Ð°Ð´Ð²Ð¾ÐºÐ°Ñ‚",
    "Ñ„Ð¸Ð½Ð°Ð½Ñ",
    "Ð¸Ð½Ð²ÐµÑÑ‚",
    "ÐºÑ€ÐµÐ´Ð¸Ñ‚",
    "Ð¿Ð°ÑÐ¿Ð¾Ñ€Ñ‚",
    "Ñ‚ÐµÐ»ÐµÑ„Ð¾Ð½",
    "email",
)
_RUDE_PATTERNS = (
    "Ð·Ð°Ñ‚ÐºÐ½Ð¸",
    "Ð¸Ð´Ð¸Ð¾Ñ‚",
    "Ñ‚ÑƒÐ¿",
    "Ð´ÐµÐ±Ð¸Ð»",
    "Ð½ÐµÐ½Ð°Ð²Ð¸Ð¶",
    "Ð¿Ð¾ÑˆÐµÐ»",
    "Ð¾Ñ‚Ð²Ð°Ð»Ð¸",
    "Ð·Ð°Ð¼Ð¾Ð»Ñ‡Ð¸",
)
_LATIN_TO_CYR = str.maketrans({
    "a": "Ð°",
    "b": "Ð²",
    "c": "Ñ",
    "e": "Ðµ",
    "h": "Ð½",
    "k": "Ðº",
    "m": "Ð¼",
    "o": "Ð¾",
    "p": "Ñ€",
    "t": "Ñ‚",
    "x": "Ñ…",
    "y": "Ñƒ",
})
_DIGIT_TO_CYR = str.maketrans({"0": "Ð¾", "3": "Ð·", "4": "Ñ‡", "6": "Ð±"})

PHONE_RE = re.compile(r"(?:\+7|8)\d{10}")
EMAIL_RE = re.compile(r"[\w.+-]+@[\w.-]+\.[A-Za-z]{2,}")
FULLNAME_RE = re.compile(r"\b[Ð-Ð¯Ð][Ð°-ÑÑ‘]+\s+[Ð-Ð¯Ð][Ð°-ÑÑ‘]+(?:\s+[Ð-Ð¯Ð][Ð°-ÑÑ‘]+)?\b")


@dataclass(slots=True)
class ModerationDecision:
    violation_type: Literal["none", "profanity", "rude", "aggression"]
    severity: int
    confidence: float
    action: Literal["none", "warn", "delete_warn", "delete_strike"]
    used_fallback: bool


@dataclass(slots=True)
class QuizAnswerDecision:
    is_correct: bool
    is_close: bool
    confidence: float
    reason: str
    used_fallback: bool


@dataclass(slots=True)
class AiProbeResult:
    ok: bool
    details: str
    latency_ms: int


@dataclass(slots=True)
class AiRuntimeStatus:
    last_error: str | None
    last_error_at: datetime | None


@dataclass(slots=True)
class AiCallOutcome:
    ok: bool
    data: dict[str, object] | None
    reason: str


_ADMIN_ALERT_COOLDOWN = timedelta(minutes=10)
_ADMIN_ALERT_NOTIFIER: Callable[[str], Awaitable[None]] | None = None
_LAST_ADMIN_ALERT_AT: dict[str, datetime] = {}
_LAST_ERROR: str | None = None
_LAST_ERROR_AT: datetime | None = None


class AiModuleClient:
    def __init__(self) -> None:
        timeout = httpx.Timeout(settings.ai_timeout_seconds)
        self._client = httpx.AsyncClient(timeout=timeout)

    async def aclose(self) -> None:
        await self._client.aclose()

    async def _maybe_alert_admin(self, reason_key: str, details: str) -> None:
        now = now_tz()
        previous = _LAST_ADMIN_ALERT_AT.get(reason_key)
        if previous and now - previous < _ADMIN_ALERT_COOLDOWN:
            return
        _LAST_ADMIN_ALERT_AT[reason_key] = now
        if _ADMIN_ALERT_NOTIFIER is None:
            return
        await _ADMIN_ALERT_NOTIFIER(details)

    async def _check_limits(self, chat_id: int) -> str | None:
        date_key = now_tz().date().isoformat()
        async for session in get_session():
            allowed, reason = await can_consume_ai(
                session,
                date_key=date_key,
                chat_id=chat_id,
                request_limit=settings.ai_daily_request_limit,
                token_limit=settings.ai_daily_token_limit,
            )
            if allowed:
                return None
            await self._maybe_alert_admin(
                f"limit:{chat_id}:{reason}",
                f"AI Ð¾Ñ‚ÐºÐ»ÑŽÑ‡ÐµÐ½ Ð¿Ð¾ Ð»Ð¸Ð¼Ð¸Ñ‚Ñƒ Ð´Ð»Ñ chat_id={chat_id}: {reason}.",
            )
            return reason
        return "Ð»Ð¸Ð¼Ð¸Ñ‚ Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½"

    async def _save_usage(self, chat_id: int, data: dict[str, object]) -> None:
        usage = data.get("usage")
        tokens_used = 0
        if isinstance(usage, dict):
            total_tokens = usage.get("total_tokens")
            if isinstance(total_tokens, (int, float)):
                tokens_used = int(total_tokens)
        date_key = now_tz().date().isoformat()
        async for session in get_session():
            await add_usage(
                session,
                date_key=date_key,
                chat_id=chat_id,
                tokens_used=tokens_used,
            )

    async def _post_with_retries(
        self,
        *,
        payload: dict[str, object],
        headers: dict[str, str],
    ) -> AiCallOutcome:
        attempts = settings.ai_retries + 1
        for attempt in range(1, attempts + 1):
            try:
                response = await self._client.post(settings.ai_api_url, json=payload, headers=headers)
            except httpx.TimeoutException:
                if attempt >= attempts:
                    return AiCallOutcome(False, None, "timeout")
                continue
            except httpx.HTTPError as exc:
                if attempt >= attempts:
                    return AiCallOutcome(False, None, f"network_error:{exc.__class__.__name__}")
                continue

            if response.status_code in {401, 403}:
                return AiCallOutcome(False, None, f"http_{response.status_code}")
            if response.status_code >= 500:
                if attempt >= attempts:
                    return AiCallOutcome(False, None, f"http_{response.status_code}")
                continue
            if response.status_code >= 400:
                return AiCallOutcome(False, None, f"http_{response.status_code}")

            try:
                data = response.json()
            except json.JSONDecodeError:
                return AiCallOutcome(False, None, "invalid_json")
            if not isinstance(data, dict):
                return AiCallOutcome(False, None, "invalid_schema")
            return AiCallOutcome(True, data, "ok")
        return AiCallOutcome(False, None, "unknown_error")

    async def _run_ai(
        self,
        *,
        payload: dict[str, object],
        chat_id: int,
        operation: str,
    ) -> AiCallOutcome:
        if not is_ai_runtime_enabled() or not settings.ai_api_url:
            return AiCallOutcome(False, None, "disabled")

        limit_reason = await self._check_limits(chat_id)
        if limit_reason:
            return AiCallOutcome(False, None, f"limit:{limit_reason}")

        headers = {"Authorization": f"Bearer {settings.ai_key}"} if settings.ai_key else {}
        result = await self._post_with_retries(payload=payload, headers=headers)
        if result.ok and result.data is not None:
            await self._save_usage(chat_id, result.data)
            return result

        _set_last_error(f"{operation}: {result.reason}")
        await self._maybe_alert_admin(
            f"error:{operation}:{result.reason}",
            f"AI Ð¾ÑˆÐ¸Ð±ÐºÐ° Ð² {operation}: {result.reason}",
        )
        return result

    async def probe(self) -> AiProbeResult:
        if not settings.ai_api_url:
            return AiProbeResult(False, "ÐÐµ Ð·Ð°Ð´Ð°Ð½ AI_API_URL.", 0)
        if not settings.ai_key:
            return AiProbeResult(False, "ÐÐµ Ð·Ð°Ð´Ð°Ð½ AI_KEY.", 0)

        payload = {
            "mode": "moderation",
            "text": "Ñ‚ÐµÑÑ‚",
            "language": "ru",
            "policy": "severity_0_3",
            "system_prompt": MODERATION_SYSTEM_PROMPT,
        }
        start = time.monotonic()
        result = await self._post_with_retries(
            payload=payload,
            headers={"Authorization": f"Bearer {settings.ai_key}"},
        )
        latency = int((time.monotonic() - start) * 1000)
        if not result.ok:
            return AiProbeResult(False, f"ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð½Ðµ Ð¿Ñ€Ð¾Ð¹Ð´ÐµÐ½Ð°: {result.reason}", latency)
        try:
            parse_moderation_response(result.data or {})
        except (ValueError, KeyError, TypeError):
            return AiProbeResult(False, "ÐžÑ‚Ð²ÐµÑ‚ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½, Ð½Ð¾ ÑÑ…ÐµÐ¼Ð° moderation Ð½ÐµÐ²Ð°Ð»Ð¸Ð´Ð½Ð°.", latency)
        return AiProbeResult(True, "AI endpoint Ð¾Ñ‚Ð²ÐµÑ‚Ð¸Ð» ÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ð¾.", latency)

    async def moderate(self, text: str, *, chat_id: int) -> ModerationDecision:
        local_decision = local_moderation(text)
        if not settings.ai_feature_moderation:
            return local_decision
        payload = {
            "mode": "moderation",
            "text": text,
            "language": "ru",
            "policy": "severity_0_3",
            "system_prompt": MODERATION_SYSTEM_PROMPT,
        }
        result = await self._run_ai(payload=payload, chat_id=chat_id, operation="moderation")
        if result.ok and result.data:
            try:
                return parse_moderation_response(result.data)
            except (ValueError, KeyError, TypeError):
                _set_last_error("moderation: invalid_schema")

        return ModerationDecision(
            violation_type=local_decision.violation_type,
            severity=local_decision.severity,
            confidence=local_decision.confidence,
            action=local_decision.action,
            used_fallback=True,
        )

    async def assistant_reply(self, prompt: str, context: list[str], *, chat_id: int) -> str:
        safe_prompt = mask_personal_data(prompt)[:1000]
        if not settings.ai_feature_assistant:
            return build_local_assistant_reply(safe_prompt)
        if not is_assistant_topic_allowed(safe_prompt):
            return "Ð¡ ÑÑ‚Ð¸Ð¼ Ð»ÑƒÑ‡ÑˆÐµ Ðº Ð¿Ñ€Ð¾Ñ„Ð¸Ð»ÑŒÐ½Ð¾Ð¼Ñƒ ÑÐ¿ÐµÑ†Ð¸Ð°Ð»Ð¸ÑÑ‚Ñƒ ðŸ™Œ Ð¯ Ñ‚ÑƒÑ‚ Ð±Ð¾Ð»ÑŒÑˆÐµ Ð¿Ñ€Ð¾ Ð¶Ð¸Ð·Ð½ÑŒ Ð´Ð¾Ð¼Ð°."

        payload = {
            "mode": "assistant",
            "language": "ru",
            "style": "brief_friendly_human",
            "max_chars": 800,
            "system_prompt": ASSISTANT_SYSTEM_PROMPT,
            "prompt": safe_prompt,
            "context": [mask_personal_data(item) for item in context[-20:]],
        }
        result = await self._run_ai(payload=payload, chat_id=chat_id, operation="assistant")
        if result.ok and result.data:
            text = str(result.data.get("reply", "")).strip()
            if text:
                return text[:800]
        return f"{_USER_FALLBACK} {build_local_assistant_reply(safe_prompt)}"

    async def evaluate_quiz_answer(
        self,
        question: str,
        correct_answer: str,
        user_answer: str,
        *,
        chat_id: int,
    ) -> QuizAnswerDecision:
        if not settings.ai_feature_quiz:
            decision = local_quiz_answer_decision(correct_answer, user_answer)
            return QuizAnswerDecision(
                is_correct=decision.is_correct,
                is_close=decision.is_close,
                confidence=decision.confidence,
                reason=decision.reason,
                used_fallback=True,
            )
        payload = {
            "mode": "quiz_judge",
            "language": "ru",
            "question": question[:1200],
            "correct_answer": correct_answer[:400],
            "user_answer": user_answer[:400],
            "policy": "contextual_equivalence_with_close_answers",
        }
        result = await self._run_ai(payload=payload, chat_id=chat_id, operation="quiz")
        if result.ok and result.data:
            try:
                return parse_quiz_answer_response(result.data)
            except (ValueError, KeyError, TypeError):
                _set_last_error("quiz: invalid_schema")

        decision = local_quiz_answer_decision(correct_answer, user_answer)
        return QuizAnswerDecision(
            is_correct=decision.is_correct,
            is_close=decision.is_close,
            confidence=decision.confidence,
            reason=decision.reason,
            used_fallback=True,
        )

    async def generate_daily_summary(self, context: str, *, chat_id: int) -> str | None:
        if not settings.ai_feature_daily_summary:
            return None
        payload = {
            "mode": "assistant",
            "language": "ru",
            "style": "brief_friendly_human",
            "max_chars": 900,
            "system_prompt": DAILY_SUMMARY_SYSTEM_PROMPT,
            "prompt": context[:3500],
            "context": [],
        }
        result = await self._run_ai(payload=payload, chat_id=chat_id, operation="daily_summary")
        if not result.ok or not result.data:
            return None
        text = str(result.data.get("reply", "")).strip()
        return text[:900] if text else None


def parse_moderation_response(data: dict[str, object]) -> ModerationDecision:
    raw_label = str(data.get("violation_type", data.get("label", "none"))).lower()
    violation_map = {
        "none": "none",
        "profanity": "profanity",
        "rude": "rude",
        "hate": "aggression",
        "threat": "aggression",
        "aggression": "aggression",
    }
    violation_type = violation_map.get(raw_label, "none")

    severity = int(data.get("severity", 0))
    confidence = float(data.get("confidence", 0.5))

    raw_action = str(data.get("action", data.get("recommended_action", "none"))).lower()
    action_map = {
        "none": "none",
        "allow": "none",
        "warn": "warn",
        "delete": "delete_warn",
        "delete_warn": "delete_warn",
        "strike": "delete_strike",
        "delete_strike": "delete_strike",
        "admin_alert": "delete_strike",
    }
    action = action_map.get(raw_action, map_action_by_severity(severity))

    severity = max(0, min(3, severity))
    confidence = max(0.0, min(1.0, confidence))
    return ModerationDecision(
        violation_type=violation_type,
        severity=severity,
        confidence=confidence,
        action=action,
        used_fallback=False,
    )


def parse_quiz_answer_response(data: dict[str, object]) -> QuizAnswerDecision:
    is_correct = bool(data.get("is_correct", False))
    is_close = bool(data.get("is_close", False))
    confidence = max(0.0, min(1.0, float(data.get("confidence", 0.5))))
    reason = str(data.get("reason", ""))[:300]
    if is_correct:
        is_close = True
    return QuizAnswerDecision(
        is_correct=is_correct,
        is_close=is_close,
        confidence=confidence,
        reason=reason,
        used_fallback=False,
    )


def local_moderation(text: str) -> ModerationDecision:
    normalized = normalize_for_profanity(text)
    if detect_profanity(normalized):
        return ModerationDecision("profanity", 3, 0.95, "delete_strike", False)
    lowered = text.lower()
    if any(pattern in lowered for pattern in _RUDE_PATTERNS):
        return ModerationDecision("rude", 1, 0.8, "warn", False)
    return ModerationDecision("none", 0, 0.99, "none", False)


def normalize_for_profanity(text: str) -> str:
    lowered = text.lower().replace("Ñ‘", "Ðµ")
    lowered = lowered.translate(_LATIN_TO_CYR).translate(_DIGIT_TO_CYR)
    lowered = re.sub(r"[\s\-_.*/]+", "", lowered)
    return lowered


def detect_profanity(normalized: str) -> bool:
    roots = ("Ñ…ÑƒÐ¹", "Ð¿Ð¸Ð·Ð´", "ÐµÐ±", "Ð±Ð»Ñ", "ÑÑƒÐº", "Ð¼ÑƒÐ´", "Ð³Ð°Ð½Ð´Ð¾Ð½")
    return any(root in normalized for root in roots)


def map_action_by_severity(severity: int) -> Literal["none", "warn", "delete_warn", "delete_strike"]:
    return {
        0: "none",
        1: "warn",
        2: "delete_warn",
        3: "delete_strike",
    }.get(severity, "none")


def mask_personal_data(text: str) -> str:
    text = PHONE_RE.sub("[ÑÐºÑ€Ñ‹Ñ‚_Ñ‚ÐµÐ»ÐµÑ„Ð¾Ð½]", text)
    text = EMAIL_RE.sub("[ÑÐºÑ€Ñ‹Ñ‚_email]", text)
    return FULLNAME_RE.sub("[ÑÐºÑ€Ñ‹Ñ‚Ð¾_Ñ„Ð¸Ð¾]", text)


def is_assistant_topic_allowed(text: str) -> bool:
    lowered = text.lower()
    if any(token in lowered for token in _FORBIDDEN_ASSISTANT_TOPICS):
        return False
    return any(token in lowered for token in _ALLOWED_ASSISTANT_TOPICS)


def build_local_assistant_reply(prompt: str) -> str:
    if "ÑˆÐ»Ð°Ð³Ð±Ð°ÑƒÐ¼" in prompt.lower():
        return "ÐŸÐ¾ ÑˆÐ»Ð°Ð³Ð±Ð°ÑƒÐ¼Ñƒ Ð»ÑƒÑ‡ÑˆÐµ Ð¿Ð¸ÑÐ°Ñ‚ÑŒ Ð² Ð¿Ñ€Ð¾Ñ„Ð¸Ð»ÑŒÐ½ÑƒÑŽ Ñ‚ÐµÐ¼Ñƒ. ÐÐ°ÐºÐ¸Ð½ÑŒÑ‚Ðµ Ð½Ð¾Ð¼ÐµÑ€ Ð°Ð²Ñ‚Ð¾ Ð¸ ÑÑƒÑ‚ÑŒ, Ð¿Ð¾Ð¼Ð¾Ð³Ñƒ ÑÐ¾Ð±Ñ€Ð°Ñ‚ÑŒ ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¸Ð¹ Ñ‚ÐµÐºÑÑ‚."
    return "Ð¥Ð¾Ñ€Ð¾ÑˆÐ¸Ð¹ Ð²Ð¾Ð¿Ñ€Ð¾Ñ. Ð”Ð¾Ð±Ð°Ð²ÑŒÑ‚Ðµ Ð°Ð´Ñ€ÐµÑ Ð¸Ð»Ð¸ Ð¿Ð¾Ð´ÑŠÐµÐ·Ð´ Ð¸ Ñ‡Ñ‚Ð¾ Ñ…Ð¾Ñ‚Ð¸Ñ‚Ðµ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð½Ð° Ð²Ñ‹Ñ…Ð¾Ð´Ðµ â€” Ñ‚Ð°Ðº Ð±Ñ‹ÑÑ‚Ñ€ÐµÐµ Ð¿Ð¾Ð´ÑÐºÐ°Ð¶ÑƒÑ‚."


def _normalize_quiz_text(text: str) -> str:
    normalized = re.sub(r"[^\w\s]+", " ", text.lower().replace("Ñ‘", "Ðµ"))
    return " ".join(normalized.split())


def local_quiz_answer_decision(correct_answer: str, user_answer: str) -> QuizAnswerDecision:
    correct = _normalize_quiz_text(correct_answer)
    answer = _normalize_quiz_text(user_answer)
    if not correct or not answer:
        return QuizAnswerDecision(False, False, 0.0, "Ð¿ÑƒÑÑ‚Ð¾Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚", False)

    if correct == answer:
        return QuizAnswerDecision(True, True, 0.95, "Ñ‚Ð¾Ñ‡Ð½Ð¾Ðµ ÑÐ¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ðµ", False)

    correct_words = set(correct.split())
    answer_words = set(answer.split())
    overlap = len(correct_words & answer_words)
    if not correct_words:
        return QuizAnswerDecision(False, False, 0.0, "Ð½ÐµÑ‚ ÑÑ‚Ð°Ð»Ð¾Ð½Ð°", False)

    ratio = overlap / len(correct_words)
    if ratio >= 0.8:
        return QuizAnswerDecision(True, True, 0.8, "Ð¿Ð¾Ñ‡Ñ‚Ð¸ Ð¿Ð¾Ð»Ð½Ñ‹Ð¹ ÑÐ¼Ñ‹ÑÐ»Ð¾Ð²Ð¾Ð¹ Ð¼Ð°Ñ‚Ñ‡", False)
    if ratio >= 0.3:
        return QuizAnswerDecision(False, True, 0.6, "Ñ‡Ð°ÑÑ‚Ð¸Ñ‡Ð½Ð¾ Ð±Ð»Ð¸Ð·ÐºÐ¸Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚", False)
    return QuizAnswerDecision(False, False, 0.2, "Ð½Ðµ ÑÐ¾Ð²Ð¿Ð°Ð´Ð°ÐµÑ‚", False)


_AI_CLIENT: AiModuleClient | None = None
_AI_RUNTIME_ENABLED: bool | None = None


def _set_last_error(error: str) -> None:
    global _LAST_ERROR, _LAST_ERROR_AT
    _LAST_ERROR = error
    _LAST_ERROR_AT = datetime.utcnow()
    logger.warning("AI degraded: %s", error)


def get_ai_runtime_status() -> AiRuntimeStatus:
    return AiRuntimeStatus(last_error=_LAST_ERROR, last_error_at=_LAST_ERROR_AT)


async def get_ai_usage_for_today(chat_id: int) -> tuple[int, int]:
    date_key = now_tz().date().isoformat()
    async for session in get_session():
        stats = await get_usage_stats(session, date_key=date_key, chat_id=chat_id)
        return stats.requests_used, stats.tokens_used
    return 0, 0


def set_ai_admin_notifier(notifier: Callable[[str], Awaitable[None]] | None) -> None:
    global _ADMIN_ALERT_NOTIFIER
    _ADMIN_ALERT_NOTIFIER = notifier


def is_ai_runtime_enabled() -> bool:
    if _AI_RUNTIME_ENABLED is None:
        return settings.ai_enabled
    return _AI_RUNTIME_ENABLED


def set_ai_runtime_enabled(value: bool) -> None:
    global _AI_RUNTIME_ENABLED
    _AI_RUNTIME_ENABLED = value


def get_ai_client() -> AiModuleClient:
    global _AI_CLIENT
    if _AI_CLIENT is None:
        _AI_CLIENT = AiModuleClient()
    return _AI_CLIENT


async def close_ai_client() -> None:
    global _AI_CLIENT
    if _AI_CLIENT is None:
        return
    await _AI_CLIENT.aclose()
    _AI_CLIENT = None
