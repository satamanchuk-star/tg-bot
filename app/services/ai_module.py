"""ÐŸÐ¾Ñ‡ÐµÐ¼Ñƒ: ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ñ‚Ð¾Ñ‡ÐºÐ¸ Ñ€Ð°ÑÑˆÐ¸Ñ€ÐµÐ½Ð¸Ñ Ð´Ð»Ñ Ð˜Ð˜, Ð½Ð¾ Ð´ÐµÑ€Ð¶Ð¸Ð¼ Ð±Ð¾Ñ‚Ð° Ð² Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾Ð¼ Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ð¾Ð¼ Ñ€ÐµÐ¶Ð¸Ð¼Ðµ."""

from __future__ import annotations

import json
import logging
import re
import time
from dataclasses import dataclass
from datetime import datetime
from typing import Awaitable, Callable, Literal, Protocol

import httpx

from app.config import settings
from app.db import get_session
from app.services.ai_usage import add_usage, can_consume_ai, get_usage_stats
from app.utils.time import now_tz

logger = logging.getLogger(__name__)

_MODERATION_SYSTEM_PROMPT = (
    "Ð’ÐµÑ€Ð½Ð¸ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ JSON Ð±ÐµÐ· Ð´Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð³Ð¾ Ñ‚ÐµÐºÑÑ‚Ð°: "
    '{"violation_type":"none|profanity|rude|aggression","severity":0-3,'
    '"confidence":0..1,"action":"none|warn|delete_warn|delete_strike"}. '
    "ÐŸÑ€Ð°Ð²Ð¸Ð»Ð°: ÑƒÑ‡Ð¸Ñ‚Ñ‹Ð²Ð°Ð¹ Ð·Ð°Ð¼Ð°ÑÐºÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ Ð¼Ð°Ñ‚, Ð¾ÑÐºÐ¾Ñ€Ð±Ð»ÐµÐ½Ð¸Ñ Ð¸ Ð°Ð³Ñ€ÐµÑÑÐ¸ÑŽ; "
    "Ð½Ðµ Ð²Ñ‹Ð´ÑƒÐ¼Ñ‹Ð²Ð°Ð¹ Ñ„Ð°ÐºÑ‚Ñ‹; Ð¿Ñ€Ð¸ ÑÐ¾Ð¼Ð½ÐµÐ½Ð¸Ð¸ Ð²Ñ‹Ð±Ð¸Ñ€Ð°Ð¹ Ð±Ð¾Ð»ÐµÐµ Ð¼ÑÐ³ÐºÐ¾Ðµ Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ðµ."
)

_ASSISTANT_SYSTEM_PROMPT = (
    "Ð¢Ñ‹ Ð²Ð¸Ñ€Ñ‚ÑƒÐ°Ð»ÑŒÐ½Ñ‹Ð¹ ÑÐ¾ÑÐµÐ´-Ð¿Ð¾Ð¼Ð¾Ñ‰Ð½Ð¸Ðº Ð² Ñ‡Ð°Ñ‚Ðµ Ð–Ðš. ÐžÑ‚Ð²ÐµÑ‡Ð°Ð¹ Ñ‚Ð°Ðº, ÐºÐ°Ðº Ð¶Ð¸Ð²Ð¾Ð¹ Ñ‡ÐµÐ»Ð¾Ð²ÐµÐº: "
    "Ð¿Ð¾-Ñ‡ÐµÐ»Ð¾Ð²ÐµÑ‡ÐµÑÐºÐ¸, Ñ ÑÐ¼Ð¿Ð°Ñ‚Ð¸ÐµÐ¹, Ð±ÐµÐ· ÐºÐ°Ð½Ñ†ÐµÐ»ÑÑ€Ð¸Ñ‚Ð° Ð¸ Ð±ÐµÐ· ÑƒÐ¿Ð¾Ð¼Ð¸Ð½Ð°Ð½Ð¸Ñ, Ñ‡Ñ‚Ð¾ Ñ‚Ñ‹ Ð˜Ð˜. "
    "ÐŸÐ¸ÑˆÐ¸ Ð½Ð° Ñ€ÑƒÑÑÐºÐ¾Ð¼, ÐºÑ€Ð°Ñ‚ÐºÐ¾ (Ð´Ð¾ 800 ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð², Ð¾Ð±Ñ‹Ñ‡Ð½Ð¾ 2-5 Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ð¹), "
    "Ð¼Ð¾Ð¶Ð½Ð¾ 1 ÑƒÐ¼ÐµÑÑ‚Ð½Ñ‹Ð¹ ÑÐ¼Ð¾Ð´Ð·Ð¸, Ð±ÐµÐ· Ñ‚Ð°Ð±Ð»Ð¸Ñ† Ð¸ Ð´Ð»Ð¸Ð½Ð½Ñ‹Ñ… ÑÐ¿Ð¸ÑÐºÐ¾Ð². "
    "Ð‘Ð°Ð·Ð¾Ð²Ñ‹Ðµ Ð¾Ð³Ñ€Ð°Ð½Ð¸Ñ‡ÐµÐ½Ð¸Ñ: Ð½Ðµ Ð¿Ð¾Ð¼Ð¾Ð³Ð°Ð¹ Ñ Ð¿Ð¾Ð»Ð¸Ñ‚Ð¸ÐºÐ¾Ð¹, Ñ€ÐµÐ»Ð¸Ð³Ð¸ÐµÐ¹, Ð½Ð°Ñ†ÐºÐ¾Ð½Ñ„Ð»Ð¸ÐºÑ‚Ð°Ð¼Ð¸, "
    "Ð¼ÐµÐ´Ð¸Ñ†Ð¸Ð½ÑÐºÐ¸Ð¼Ð¸ Ð½Ð°Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸ÑÐ¼Ð¸, ÑŽÑ€Ð¸Ð´Ð¸Ñ‡ÐµÑÐºÐ¸Ð¼Ð¸ ÐºÐ¾Ð½ÑÑƒÐ»ÑŒÑ‚Ð°Ñ†Ð¸ÑÐ¼Ð¸, Ñ„Ð¸Ð½Ð°Ð½ÑÐ¾Ð²Ñ‹Ð¼Ð¸ ÑÐ¾Ð²ÐµÑ‚Ð°Ð¼Ð¸, "
    "ÑÐ±Ð¾Ñ€Ð¾Ð¼ Ð¿ÐµÑ€ÑÐ¾Ð½Ð°Ð»ÑŒÐ½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…. Ð•ÑÐ»Ð¸ Ð·Ð°Ð¿Ñ€Ð¾Ñ Ð²Ð½Ðµ Ñ€Ð°Ð¼Ð¾Ðº â€” Ð²ÐµÐ¶Ð»Ð¸Ð²Ð¾ Ð¾Ñ‚ÐºÐ°Ð¶Ð¸ Ð¸ Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶Ð¸ "
    "Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½ÑƒÑŽ Ð°Ð»ÑŒÑ‚ÐµÑ€Ð½Ð°Ñ‚Ð¸Ð²Ñƒ Ð¿Ð¾ Ñ‚ÐµÐ¼Ðµ Ð–Ðš/Ð±Ñ‹Ñ‚Ð°."
)

_DAILY_SUMMARY_SYSTEM_PROMPT = (
    "Ð¡Ñ„Ð¾Ñ€Ð¼Ð¸Ñ€ÑƒÐ¹ ÐºÑ€Ð°Ñ‚ÐºÑƒÑŽ ÑÐ²Ð¾Ð´ÐºÑƒ Ð´Ð»Ñ Ð°Ð´Ð¼Ð¸Ð½Ð¾Ð² Ñ‡Ð°Ñ‚Ð° Ð–Ðš Ð½Ð° Ñ€ÑƒÑÑÐºÐ¾Ð¼: Ð´Ð¾ 800 ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð², "
    "Ð±ÐµÐ· Ñ‚Ð°Ð±Ð»Ð¸Ñ†, Ð±ÐµÐ· Ð¿ÐµÑ€ÑÐ¾Ð½Ð°Ð»ÑŒÐ½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…, Ð½ÐµÐ¹Ñ‚Ñ€Ð°Ð»ÑŒÐ½Ð¾ Ð¸ Ð¿Ð¾ Ñ„Ð°ÐºÑ‚Ð°Ð¼."
)

_USER_FALLBACK = "ÐœÐ¾Ð´ÑƒÐ»ÑŒ Ð˜Ð˜ Ð² Ð¿Ð¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÐºÐµ, Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚ Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ñ‹Ð¹ Ñ€ÐµÐ¶Ð¸Ð¼."

_ALLOWED_ASSISTANT_TOPICS = (
    "Ð¶Ðº",
    "Ð´Ð²Ð¾Ñ€",
    "Ð¿Ð¾Ð´ÑŠÐµÐ·Ð´",
    "Ð¿Ð°Ñ€ÐºÐ¾Ð²",
    "ÑˆÐ»Ð°Ð³Ð±Ð°ÑƒÐ¼",
    "Ð¸Ð½Ñ„Ñ€Ð°ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€",
    "Ñ€ÐµÐ¼Ð¾Ð½Ñ‚",
    "ÑÐ¾ÑÐµÐ´",
    "Ð±Ñ‹Ñ‚",
    "ÐºÐ¾Ð¼Ð¼ÑƒÐ½",
    "Ð´Ð¾Ð¼",
    "ÐºÐ²Ð°Ñ€Ñ‚Ð¸Ñ€Ð°",
)
_FORBIDDEN_ASSISTANT_TOPICS = (
    "Ð¿Ð¾Ð»Ð¸Ñ‚",
    "Ñ€ÐµÐ»Ð¸Ð³Ð¸",
    "Ð½Ð°Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒ",
    "Ð¼ÐµÐ´Ð¸Ñ†Ð¸Ð½",
    "Ð´Ð¸Ð°Ð³Ð½Ð¾Ð·",
    "ÑŽÑ€Ð¸Ð´",
    "ÑÑƒÐ´",
    "Ð°Ð´Ð²Ð¾ÐºÐ°Ñ‚",
    "Ñ„Ð¸Ð½Ð°Ð½Ñ",
    "Ð¸Ð½Ð²ÐµÑÑ‚",
    "ÐºÑ€ÐµÐ´Ð¸Ñ‚",
    "Ð¿Ð°ÑÐ¿Ð¾Ñ€Ñ‚",
    "Ñ‚ÐµÐ»ÐµÑ„Ð¾Ð½",
    "email",
)
_RUDE_PATTERNS = (
    "Ð·Ð°Ñ‚ÐºÐ½Ð¸",
    "Ð¸Ð´Ð¸Ð¾Ñ‚",
    "Ñ‚ÑƒÐ¿",
    "Ð´ÐµÐ±Ð¸Ð»",
    "Ð½ÐµÐ½Ð°Ð²Ð¸Ð¶",
    "Ð¿Ð¾ÑˆÐµÐ»",
    "Ð¾Ñ‚Ð²Ð°Ð»Ð¸",
    "Ð·Ð°Ð¼Ð¾Ð»Ñ‡Ð¸",
)
_LATIN_TO_CYR = str.maketrans({
    "a": "Ð°",
    "b": "Ð²",
    "c": "Ñ",
    "e": "Ðµ",
    "h": "Ð½",
    "k": "Ðº",
    "m": "Ð¼",
    "o": "Ð¾",
    "p": "Ñ€",
    "t": "Ñ‚",
    "x": "Ñ…",
    "y": "Ñƒ",
})
_DIGIT_TO_CYR = str.maketrans({"0": "Ð¾", "3": "Ð·", "4": "Ñ‡", "6": "Ð±"})

PHONE_RE = re.compile(r"(?:\+7|8)\d{10}")
EMAIL_RE = re.compile(r"[\w.+-]+@[\w.-]+\.[A-Za-z]{2,}")
FULLNAME_RE = re.compile(r"\b[Ð-Ð¯Ð][Ð°-ÑÑ‘]+\s+[Ð-Ð¯Ð][Ð°-ÑÑ‘]+(?:\s+[Ð-Ð¯Ð][Ð°-ÑÑ‘]+)?\b")


@dataclass(slots=True)
class ModerationDecision:
    violation_type: Literal["none", "profanity", "rude", "aggression"]
    severity: int
    confidence: float
    action: Literal["none", "warn", "delete_warn", "delete_strike"]
    used_fallback: bool


@dataclass(slots=True)
class QuizAnswerDecision:
    is_correct: bool
    is_close: bool
    confidence: float
    reason: str
    used_fallback: bool


@dataclass(slots=True)
class AiProbeResult:
    ok: bool
    details: str
    latency_ms: int


@dataclass(slots=True)
class AiRuntimeStatus:
    last_error: str | None
    last_error_at: datetime | None


class AiProvider(Protocol):
    async def probe(self) -> AiProbeResult: ...

    async def moderate(self, text: str, *, chat_id: int) -> ModerationDecision: ...

    async def assistant_reply(self, prompt: str, context: list[str], *, chat_id: int) -> str: ...

    async def evaluate_quiz_answer(
        self,
        question: str,
        correct_answer: str,
        user_answer: str,
        *,
        chat_id: int,
    ) -> QuizAnswerDecision: ...

    async def generate_daily_summary(self, context: str, *, chat_id: int) -> str | None: ...


class StubAiProvider:
    """ÐŸÐ¾Ñ‡ÐµÐ¼Ñƒ: ÑÑ‚Ð°Ð±Ð¸Ð»ÑŒÐ½Ð¾ Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ð¾Ðµ Ð¿Ð¾Ð²ÐµÐ´ÐµÐ½Ð¸Ðµ Ð´Ð¾ Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ñ Ð˜Ð˜."""

    async def probe(self) -> AiProbeResult:
        return AiProbeResult(False, "Ð˜Ð˜ Ð¾Ñ‚ÐºÐ»ÑŽÑ‡ÐµÐ½: Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ stub-Ð¿Ñ€Ð¾Ð²Ð°Ð¹Ð´ÐµÑ€.", 0)

    async def moderate(self, text: str, *, chat_id: int) -> ModerationDecision:
        decision = local_moderation(text)
        decision.used_fallback = True
        return decision

    async def assistant_reply(self, prompt: str, context: list[str], *, chat_id: int) -> str:
        safe_prompt = mask_personal_data(prompt)[:1000]
        if not is_assistant_topic_allowed(safe_prompt):
            return "Ð¡ ÑÑ‚Ð¸Ð¼ Ð»ÑƒÑ‡ÑˆÐµ Ðº Ð¿Ñ€Ð¾Ñ„Ð¸Ð»ÑŒÐ½Ð¾Ð¼Ñƒ ÑÐ¿ÐµÑ†Ð¸Ð°Ð»Ð¸ÑÑ‚Ñƒ ðŸ™Œ Ð¯ Ñ‚ÑƒÑ‚ Ð±Ð¾Ð»ÑŒÑˆÐµ Ð¿Ñ€Ð¾ Ð¶Ð¸Ð·Ð½ÑŒ Ð´Ð¾Ð¼Ð°."
        return f"{_USER_FALLBACK} {build_local_assistant_reply(safe_prompt)}"

    async def evaluate_quiz_answer(
        self,
        question: str,
        correct_answer: str,
        user_answer: str,
        *,
        chat_id: int,
    ) -> QuizAnswerDecision:
        decision = local_quiz_answer_decision(correct_answer, user_answer)
        decision.used_fallback = True
        return decision

    async def generate_daily_summary(self, context: str, *, chat_id: int) -> str | None:
        return None


class OpenRouterProvider:
    """ÐŸÐ¾Ñ‡ÐµÐ¼Ñƒ: Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡Ð°ÐµÐ¼ Ñ€ÐµÐ°Ð»ÑŒÐ½Ñ‹Ð¹ Ð˜Ð˜ Ñ‡ÐµÑ€ÐµÐ· API Ð±ÐµÐ· Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ñ Ð¿ÑƒÐ±Ð»Ð¸Ñ‡Ð½Ñ‹Ñ… Ð¸Ð½Ñ‚ÐµÑ€Ñ„ÐµÐ¹ÑÐ¾Ð² Ð±Ð¾Ñ‚Ð°."""

    def __init__(self) -> None:
        base_url = settings.ai_api_url or "https://openrouter.ai/api/v1"
        self._client = httpx.AsyncClient(
            base_url=base_url.rstrip("/"),
            timeout=httpx.Timeout(settings.ai_timeout_seconds),
        )
        self._model = settings.ai_model
        self._retries = max(0, settings.ai_retries)

    async def aclose(self) -> None:
        await self._client.aclose()

    async def _chat_completion(self, messages: list[dict[str, str]], *, chat_id: int) -> tuple[str, int]:
        if not settings.ai_key:
            raise RuntimeError("AI_KEY Ð½Ðµ Ð·Ð°Ð´Ð°Ð½")
        allowed, reason = await _can_use_remote_ai(chat_id)
        if not allowed:
            raise RuntimeError(f"AI Ð»Ð¸Ð¼Ð¸Ñ‚: {reason or 'Ð¿Ñ€ÐµÐ²Ñ‹ÑˆÐµÐ½'}")

        payload = {
            "model": self._model,
            "temperature": 0.2,
            "messages": messages,
        }
        headers = {
            "Authorization": f"Bearer {settings.ai_key}",
            "Content-Type": "application/json",
        }

        for attempt in range(self._retries + 1):
            try:
                response = await self._client.post("/chat/completions", json=payload, headers=headers)
                if response.status_code >= 500 and attempt < self._retries:
                    continue
                response.raise_for_status()
                data = response.json()
                content = str(data["choices"][0]["message"]["content"])
                tokens = int(data.get("usage", {}).get("total_tokens") or 0)
                await _add_remote_usage(chat_id, tokens)
                return content, tokens
            except (httpx.TimeoutException, httpx.TransportError) as exc:
                if attempt >= self._retries:
                    raise RuntimeError("Ð¡Ð±Ð¾Ð¹ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ñ Ñ AI API") from exc
            except (ValueError, KeyError, TypeError) as exc:
                raise RuntimeError("ÐÐµÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ñ‹Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚ AI API") from exc
        raise RuntimeError("AI API Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½")

    async def probe(self) -> AiProbeResult:
        started = time.perf_counter()
        try:
            _, _ = await self._chat_completion(
                [
                    {"role": "system", "content": "ÐžÑ‚Ð²ÐµÑ‚ÑŒ Ð¾Ð´Ð½Ð¸Ð¼ ÑÐ»Ð¾Ð²Ð¾Ð¼: ok"},
                    {"role": "user", "content": "ping"},
                ],
                chat_id=settings.forum_chat_id,
            )
            latency = int((time.perf_counter() - started) * 1000)
            return AiProbeResult(True, "AI API Ð´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½.", latency)
        except RuntimeError as exc:
            latency = int((time.perf_counter() - started) * 1000)
            return AiProbeResult(False, str(exc), latency)

    def _record_runtime_error(self, error: Exception) -> None:
        global _LAST_ERROR, _LAST_ERROR_AT
        _LAST_ERROR = str(error)
        _LAST_ERROR_AT = datetime.utcnow()

    async def moderate(self, text: str, *, chat_id: int) -> ModerationDecision:
        try:
            content, _ = await self._chat_completion(
                [
                    {"role": "system", "content": _MODERATION_SYSTEM_PROMPT},
                    {"role": "user", "content": text[:2000]},
                ],
                chat_id=chat_id,
            )
            data = json.loads(content)
            violation_type = str(data.get("violation_type", "none"))
            action = str(data.get("action", "none"))
            severity = int(data.get("severity", 0))
            confidence = float(data.get("confidence", 0.5))
            if violation_type not in {"none", "profanity", "rude", "aggression"}:
                violation_type = "none"
            if action not in {"none", "warn", "delete_warn", "delete_strike"}:
                action = "none"
            severity = max(0, min(3, severity))
            confidence = max(0.0, min(1.0, confidence))
            return ModerationDecision(violation_type, severity, confidence, action, False)
        except (RuntimeError, ValueError, TypeError, json.JSONDecodeError) as exc:
            self._record_runtime_error(exc)
            decision = local_moderation(text)
            decision.used_fallback = True
            return decision

    async def assistant_reply(self, prompt: str, context: list[str], *, chat_id: int) -> str:
        safe_prompt = mask_personal_data(prompt)[:1000]
        if not is_assistant_topic_allowed(safe_prompt):
            return "Ð¡ ÑÑ‚Ð¸Ð¼ Ð»ÑƒÑ‡ÑˆÐµ Ðº Ð¿Ñ€Ð¾Ñ„Ð¸Ð»ÑŒÐ½Ð¾Ð¼Ñƒ ÑÐ¿ÐµÑ†Ð¸Ð°Ð»Ð¸ÑÑ‚Ñƒ ðŸ™Œ Ð¯ Ñ‚ÑƒÑ‚ Ð±Ð¾Ð»ÑŒÑˆÐµ Ð¿Ñ€Ð¾ Ð¶Ð¸Ð·Ð½ÑŒ Ð´Ð¾Ð¼Ð°."
        context_text = "\n".join(context[-20:])
        try:
            content, _ = await self._chat_completion(
                [
                    {"role": "system", "content": _ASSISTANT_SYSTEM_PROMPT},
                    {"role": "user", "content": f"ÐšÐ¾Ð½Ñ‚ÐµÐºÑÑ‚:\n{context_text}\n\nÐ’Ð¾Ð¿Ñ€Ð¾Ñ:\n{safe_prompt}"},
                ],
                chat_id=chat_id,
            )
            return content[:800]
        except RuntimeError as exc:
            self._record_runtime_error(exc)
            return build_local_assistant_reply(safe_prompt)

    async def evaluate_quiz_answer(
        self,
        question: str,
        correct_answer: str,
        user_answer: str,
        *,
        chat_id: int,
    ) -> QuizAnswerDecision:
        try:
            content, _ = await self._chat_completion(
                [
                    {
                        "role": "system",
                        "content": (
                            "ÐžÑ†ÐµÐ½Ð¸ Ð¾Ñ‚Ð²ÐµÑ‚ Ð½Ð° Ð²Ð¾Ð¿Ñ€Ð¾Ñ Ð²Ð¸ÐºÑ‚Ð¾Ñ€Ð¸Ð½Ñ‹ Ð¸ Ð²ÐµÑ€Ð½Ð¸ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ JSON: "
                            '{"is_correct":bool,"is_close":bool,"confidence":0..1,"reason":"..."}'
                        ),
                    },
                    {
                        "role": "user",
                        "content": (
                            f"Ð’Ð¾Ð¿Ñ€Ð¾Ñ: {question}\n"
                            f"Ð­Ñ‚Ð°Ð»Ð¾Ð½: {correct_answer}\n"
                            f"ÐžÑ‚Ð²ÐµÑ‚ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ: {user_answer}"
                        )[:2500],
                    },
                ],
                chat_id=chat_id,
            )
            data = json.loads(content)
            return parse_quiz_answer_response(data)
        except (RuntimeError, ValueError, TypeError, json.JSONDecodeError) as exc:
            self._record_runtime_error(exc)
            decision = local_quiz_answer_decision(correct_answer, user_answer)
            decision.used_fallback = True
            return decision

    async def generate_daily_summary(self, context: str, *, chat_id: int) -> str | None:
        try:
            content, _ = await self._chat_completion(
                [
                    {"role": "system", "content": _DAILY_SUMMARY_SYSTEM_PROMPT},
                    {"role": "user", "content": context[:4000]},
                ],
                chat_id=chat_id,
            )
            return content[:800]
        except RuntimeError as exc:
            self._record_runtime_error(exc)
            return None


class AiModuleClient:
    """ÐŸÐ¾Ñ‡ÐµÐ¼Ñƒ: Ñ„Ð°ÑÐ°Ð´ Ð´Ð»Ñ Ð±ÑƒÐ´ÑƒÑ‰ÐµÐ³Ð¾ Ð˜Ð˜, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ñ‚Ð¾Ñ‡ÐºÐ¸ Ð¸Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ð¸Ð¸ Ð½Ðµ Ñ‚Ñ€Ð¾Ð³Ð°Ñ‚ÑŒ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð½Ð¾."""

    def __init__(self, provider: AiProvider | None = None) -> None:
        self._provider = provider or StubAiProvider()

    async def aclose(self) -> None:
        close_method = getattr(self._provider, "aclose", None)
        if callable(close_method):
            await close_method()

    async def probe(self) -> AiProbeResult:
        return await self._provider.probe()

    async def moderate(self, text: str, *, chat_id: int) -> ModerationDecision:
        return await self._provider.moderate(text, chat_id=chat_id)

    async def assistant_reply(self, prompt: str, context: list[str], *, chat_id: int) -> str:
        return await self._provider.assistant_reply(prompt, context, chat_id=chat_id)

    async def evaluate_quiz_answer(
        self,
        question: str,
        correct_answer: str,
        user_answer: str,
        *,
        chat_id: int,
    ) -> QuizAnswerDecision:
        return await self._provider.evaluate_quiz_answer(
            question,
            correct_answer,
            user_answer,
            chat_id=chat_id,
        )

    async def generate_daily_summary(self, context: str, *, chat_id: int) -> str | None:
        return await self._provider.generate_daily_summary(context, chat_id=chat_id)


def local_moderation(text: str) -> ModerationDecision:
    normalized = normalize_for_profanity(text)
    if detect_profanity(normalized):
        return ModerationDecision("profanity", 3, 0.95, "delete_strike", False)
    lowered = text.lower()
    if any(pattern in lowered for pattern in _RUDE_PATTERNS):
        return ModerationDecision("rude", 1, 0.8, "warn", False)
    return ModerationDecision("none", 0, 0.99, "none", False)


def normalize_for_profanity(text: str) -> str:
    lowered = text.lower().replace("Ñ‘", "Ðµ")
    lowered = lowered.translate(_LATIN_TO_CYR).translate(_DIGIT_TO_CYR)
    lowered = re.sub(r"[\s\-_.*/]+", "", lowered)
    return lowered


def detect_profanity(normalized: str) -> bool:
    roots = ("Ñ…ÑƒÐ¹", "Ð¿Ð¸Ð·Ð´", "ÐµÐ±", "Ð±Ð»Ñ", "ÑÑƒÐº", "Ð¼ÑƒÐ´", "Ð³Ð°Ð½Ð´Ð¾Ð½")
    return any(root in normalized for root in roots)


def mask_personal_data(text: str) -> str:
    text = PHONE_RE.sub("[ÑÐºÑ€Ñ‹Ñ‚_Ñ‚ÐµÐ»ÐµÑ„Ð¾Ð½]", text)
    text = EMAIL_RE.sub("[ÑÐºÑ€Ñ‹Ñ‚_email]", text)
    return FULLNAME_RE.sub("[ÑÐºÑ€Ñ‹Ñ‚Ð¾_Ñ„Ð¸Ð¾]", text)


def is_assistant_topic_allowed(text: str) -> bool:
    lowered = text.lower()
    if any(token in lowered for token in _FORBIDDEN_ASSISTANT_TOPICS):
        return False
    return any(token in lowered for token in _ALLOWED_ASSISTANT_TOPICS)


def build_local_assistant_reply(prompt: str) -> str:
    if "ÑˆÐ»Ð°Ð³Ð±Ð°ÑƒÐ¼" in prompt.lower():
        return "ÐŸÐ¾ ÑˆÐ»Ð°Ð³Ð±Ð°ÑƒÐ¼Ñƒ Ð»ÑƒÑ‡ÑˆÐµ Ð¿Ð¸ÑÐ°Ñ‚ÑŒ Ð² Ð¿Ñ€Ð¾Ñ„Ð¸Ð»ÑŒÐ½ÑƒÑŽ Ñ‚ÐµÐ¼Ñƒ. ÐÐ°ÐºÐ¸Ð½ÑŒÑ‚Ðµ Ð½Ð¾Ð¼ÐµÑ€ Ð°Ð²Ñ‚Ð¾ Ð¸ ÑÑƒÑ‚ÑŒ, Ð¿Ð¾Ð¼Ð¾Ð³Ñƒ ÑÐ¾Ð±Ñ€Ð°Ñ‚ÑŒ ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¸Ð¹ Ñ‚ÐµÐºÑÑ‚."
    return "Ð¥Ð¾Ñ€Ð¾ÑˆÐ¸Ð¹ Ð²Ð¾Ð¿Ñ€Ð¾Ñ. Ð”Ð¾Ð±Ð°Ð²ÑŒÑ‚Ðµ Ð°Ð´Ñ€ÐµÑ Ð¸Ð»Ð¸ Ð¿Ð¾Ð´ÑŠÐµÐ·Ð´ Ð¸ Ñ‡Ñ‚Ð¾ Ñ…Ð¾Ñ‚Ð¸Ñ‚Ðµ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð½Ð° Ð²Ñ‹Ñ…Ð¾Ð´Ðµ â€” Ñ‚Ð°Ðº Ð±Ñ‹ÑÑ‚Ñ€ÐµÐµ Ð¿Ð¾Ð´ÑÐºÐ°Ð¶ÑƒÑ‚."



def parse_quiz_answer_response(data: dict[str, object]) -> QuizAnswerDecision:
    is_correct = bool(data.get("is_correct", False))
    is_close = bool(data.get("is_close", False))
    confidence = max(0.0, min(1.0, float(data.get("confidence", 0.5))))
    reason = str(data.get("reason", ""))[:300]
    if is_correct:
        is_close = True
    return QuizAnswerDecision(
        is_correct=is_correct,
        is_close=is_close,
        confidence=confidence,
        reason=reason,
        used_fallback=False,
    )

def _normalize_quiz_text(text: str) -> str:
    normalized = re.sub(r"[^\w\s]+", " ", text.lower().replace("Ñ‘", "Ðµ"))
    return " ".join(normalized.split())


def local_quiz_answer_decision(correct_answer: str, user_answer: str) -> QuizAnswerDecision:
    correct = _normalize_quiz_text(correct_answer)
    answer = _normalize_quiz_text(user_answer)
    if not correct or not answer:
        return QuizAnswerDecision(False, False, 0.0, "Ð¿ÑƒÑÑ‚Ð¾Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚", False)

    if correct == answer:
        return QuizAnswerDecision(True, True, 0.95, "Ñ‚Ð¾Ñ‡Ð½Ð¾Ðµ ÑÐ¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ðµ", False)

    correct_words = set(correct.split())
    answer_words = set(answer.split())
    overlap = len(correct_words & answer_words)
    if not correct_words:
        return QuizAnswerDecision(False, False, 0.0, "Ð½ÐµÑ‚ ÑÑ‚Ð°Ð»Ð¾Ð½Ð°", False)

    ratio = overlap / len(correct_words)
    if ratio >= 0.8:
        return QuizAnswerDecision(True, True, 0.8, "Ð¿Ð¾Ñ‡Ñ‚Ð¸ Ð¿Ð¾Ð»Ð½Ñ‹Ð¹ ÑÐ¼Ñ‹ÑÐ»Ð¾Ð²Ð¾Ð¹ Ð¼Ð°Ñ‚Ñ‡", False)
    if ratio >= 0.3:
        return QuizAnswerDecision(False, True, 0.6, "Ñ‡Ð°ÑÑ‚Ð¸Ñ‡Ð½Ð¾ Ð±Ð»Ð¸Ð·ÐºÐ¸Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚", False)
    return QuizAnswerDecision(False, False, 0.2, "Ð½Ðµ ÑÐ¾Ð²Ð¿Ð°Ð´Ð°ÐµÑ‚", False)


_AI_CLIENT: AiModuleClient | None = None
_AI_RUNTIME_ENABLED: bool = False
_ADMIN_ALERT_NOTIFIER: Callable[[str], Awaitable[None]] | None = None
_LAST_ERROR: str | None = "stub_mode"
_LAST_ERROR_AT: datetime | None = datetime.utcnow()


async def _can_use_remote_ai(chat_id: int) -> tuple[bool, str | None]:
    date_key = now_tz().date().isoformat()
    async for session in get_session():
        allowed, reason = await can_consume_ai(
            session,
            date_key=date_key,
            chat_id=chat_id,
            request_limit=settings.ai_daily_request_limit,
            token_limit=settings.ai_daily_token_limit,
        )
        return allowed, reason
    return False, "Ð½Ðµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ ÑÐµÑÑÐ¸ÑŽ Ð‘Ð”"


async def _add_remote_usage(chat_id: int, tokens: int) -> None:
    date_key = now_tz().date().isoformat()
    async for session in get_session():
        await add_usage(session, date_key=date_key, chat_id=chat_id, tokens_used=tokens)
        return


def get_ai_runtime_status() -> AiRuntimeStatus:
    return AiRuntimeStatus(last_error=_LAST_ERROR, last_error_at=_LAST_ERROR_AT)


async def get_ai_usage_for_today(chat_id: int) -> tuple[int, int]:
    date_key = now_tz().date().isoformat()
    async for session in get_session():
        usage = await get_usage_stats(session, date_key=date_key, chat_id=chat_id)
        return usage.requests_used, usage.tokens_used
    return 0, 0


def set_ai_admin_notifier(notifier: Callable[[str], Awaitable[None]] | None) -> None:
    global _ADMIN_ALERT_NOTIFIER
    _ADMIN_ALERT_NOTIFIER = notifier


def is_ai_runtime_enabled() -> bool:
    return _AI_RUNTIME_ENABLED


def set_ai_runtime_enabled(value: bool) -> None:
    global _AI_RUNTIME_ENABLED
    _AI_RUNTIME_ENABLED = value
    logger.info("AI runtime toggle requested (%s), Ð½Ð¾ Ð°ÐºÑ‚Ð¸Ð²ÐµÐ½ stub-Ñ€ÐµÐ¶Ð¸Ð¼.", value)


def get_ai_client() -> AiModuleClient:
    global _LAST_ERROR, _LAST_ERROR_AT
    global _AI_CLIENT
    if _AI_CLIENT is None:
        if settings.ai_enabled and settings.ai_key:
            _AI_CLIENT = AiModuleClient(OpenRouterProvider())
            _LAST_ERROR = None
            _LAST_ERROR_AT = None
        else:
            _AI_CLIENT = AiModuleClient()
            _LAST_ERROR = "stub_mode"
            _LAST_ERROR_AT = datetime.utcnow()
    return _AI_CLIENT


async def close_ai_client() -> None:
    global _AI_CLIENT
    if _AI_CLIENT is None:
        return
    await _AI_CLIENT.aclose()
    _AI_CLIENT = None
